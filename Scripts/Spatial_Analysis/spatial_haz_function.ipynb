{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d927d3-4769-4595-8aa8-0ad8ec50e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import arcpy\n",
    "import arcpy.sa as sa\n",
    "import arcpy.mp as mp\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601f882-d8bc-4f31-9e88-0a194b801825",
   "metadata": {},
   "source": [
    "#### Define a function to clean the output folder of all files. But it can't ignore locks, eg if a file is open in Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d976850-16ea-493b-abcd-557d6d7edc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_folder(output_folder_path):\n",
    "    for filename in os.listdir(output_folder_path):\n",
    "        file_path = os.path.join(output_folder_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.remove(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                import shutil\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not delete {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5d5d5-9462-4a9c-83e3-8fdb1759e1c7",
   "metadata": {},
   "source": [
    "#### Define a function to run zonal statistics. The variables are:  \n",
    "##### zone_fc - feature class to act as the aggregator, for us that's trimmed CBG polygons  \n",
    "##### zone_field - the field that acts as a unique identifier, for us that will be GEOIDFQ  \n",
    "##### raster_path - the path to the raster file used for the analysis\n",
    "##### output_folder - the path to the output folder for the DBF file containing statistics\n",
    "##### stat_type - the type of statistics, MEAN, MAXIMUM, MINIMUM, etc  \n",
    "#####\n",
    "#### Coordinate system must match between polygon and rasters being analyzed!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10b8d9a-ab8b-4c71-95bc-7ee3fde72e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_zonal_stats(zone_fc, zone_field, raster_path, output_folder, stat_type):\n",
    "    import os\n",
    "    import arcpy\n",
    "    import arcpy.sa as sa\n",
    "    arcpy.CheckOutExtension(\"Spatial\")\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    # Sanitize raster base name for use in DBF field/table names (max 8 chars is safest for DBF)\n",
    "    raster_base = os.path.splitext(os.path.basename(raster_path))[0]\n",
    "    raster_base_clean = raster_base.replace(\" \", \"_\")[:32]  # Max safe length for filename\n",
    "    stat_type_clean = stat_type.lower()\n",
    "\n",
    "    out_table_name = f\"{raster_base_clean}_{stat_type_clean}.dbf\"\n",
    "\n",
    "    out_table_path = os.path.join(output_folder, \"temp\", out_table_name)\n",
    "    \n",
    "    out_temp_folder = os.path.join(output_folder, \"temp\")\n",
    "    \n",
    "    #Create OUTPUT folder which was pasased in as variable, and nested TEMP folder if they don't exist already\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(out_temp_folder, exist_ok=True)\n",
    "    \n",
    "\n",
    "    # Run zonal statistics\n",
    "    sa.ZonalStatisticsAsTable(\n",
    "        in_zone_data=zone_fc,\n",
    "        zone_field=zone_field,\n",
    "        in_value_raster=raster_path,\n",
    "        out_table=out_table_path,\n",
    "        statistics_type=stat_type,\n",
    "        ignore_nodata=\"DATA\"\n",
    "    )\n",
    "    \n",
    "    return out_table_path  # return path to the table so you can print for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4140f4-b54d-48b7-8070-417d2e0af646",
   "metadata": {},
   "source": [
    "#### Function to calculate whether the zone_fc vector layer has any contact with the vector_path layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba67ea6-196a-4242-b508-c7c7a5d3570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_vector_match(zone_fc, zone_field, vector_path, output_folder, match_type):\n",
    "    import os\n",
    "    import arcpy\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    # Sanitize base name\n",
    "    vector_base = os.path.splitext(os.path.basename(vector_path))[0]\n",
    "    vector_base_clean = vector_base.replace(\" \", \"_\")[:32]\n",
    "    match_type_clean = match_type.lower()\n",
    "\n",
    "    # Output table name\n",
    "    out_table_name = f\"{vector_base_clean}_{match_type_clean}.dbf\"\n",
    "    out_table_path = os.path.join(output_folder, \"temp\", out_table_name)\n",
    "\n",
    "    out_temp_folder = os.path.join(output_folder, \"temp\")\n",
    "    \n",
    "    #Create OUTPUT folder which was pasased in as variable, and nested TEMP folder if they don't exist already. Clean them if they do\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(out_temp_folder, exist_ok=True)\n",
    "\n",
    "    # Create feature layers\n",
    "    zone_layer = \"zone_layer\"\n",
    "    vector_layer = \"vector_layer\"\n",
    "    arcpy.MakeFeatureLayer_management(zone_fc, zone_layer)\n",
    "    arcpy.MakeFeatureLayer_management(vector_path, vector_layer)\n",
    "\n",
    "    # New code to dissolve\n",
    "    dissolved_vector = os.path.join(out_temp_folder, \"dissolved_temp.shp\")\n",
    "    # Delete existing output to avoid overwrite issues\n",
    "    if arcpy.Exists(dissolved_vector):\n",
    "        arcpy.management.Delete(dissolved_vector)\n",
    "    arcpy.management.Dissolve(vector_path, dissolved_vector)\n",
    "    \n",
    "    # Perform spatial join\n",
    "    temp_join = \"in_memory/temp_join\"\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=zone_layer,\n",
    "        join_features=dissolved_vector,\n",
    "        out_feature_class=temp_join,\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        join_type=\"KEEP_ALL\",\n",
    "        match_option=match_type.upper()  # INTERSECT, WITHIN, CONTAINS, etc.\n",
    "    )\n",
    "\n",
    "    # Add a binary 1/0 field indicating presence/absence of match\n",
    "    fieldname_short = f\"{match_type_clean}\"[:10]  # Ensure DBF-safe\n",
    "    arcpy.management.AddField(temp_join, fieldname_short, \"SHORT\")\n",
    "\n",
    "    # Determine if match occurred by checking for nulls in join fields\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=temp_join,\n",
    "        field=fieldname_short,\n",
    "        expression=\"0 if !Join_Count! is None or !Join_Count! == 0 else 1\",\n",
    "        expression_type=\"PYTHON3\"\n",
    "    )\n",
    "\n",
    "    # Export table\n",
    "    arcpy.conversion.TableToTable(temp_join, out_temp_folder, out_table_name)\n",
    "\n",
    "    return out_table_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5196b6-7eca-4103-8373-6b72299b42b6",
   "metadata": {},
   "source": [
    "#### Function to calculate % overlap between zone_fc vector layer has any contact with the vector_path layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b4441a-26c1-4c64-b175-e88d55464049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_vector_pct(zone_fc, zone_field, vector_path, output_folder):\n",
    "    import os\n",
    "    import arcpy\n",
    "\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "    # Clean name for output (based on intersecting feature class)\n",
    "    vector_base = os.path.splitext(os.path.basename(vector_path))[0]\n",
    "    out_name = f\"{vector_base[:32]}_pct.shp\"\n",
    "    out_path = os.path.join(output_folder, \"temp\", out_name)\n",
    "\n",
    "    out_temp_folder = os.path.join(output_folder, \"temp\")\n",
    "    \n",
    "    #Create OUTPUT folder which was pasased in as variable, and nested TEMP folder if they don't exist already. Clean them if they do\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(out_temp_folder, exist_ok=True)\n",
    "\n",
    "    # New code to dissolve\n",
    "    dissolved_vector = os.path.join(out_temp_folder, \"dissolved_temp.shp\")\n",
    "    # Delete existing output to avoid overwrite issues\n",
    "    if arcpy.Exists(dissolved_vector):\n",
    "        arcpy.management.Delete(dissolved_vector)\n",
    "    arcpy.management.Dissolve(vector_path, dissolved_vector)\n",
    "    \n",
    "    # Step 1: Intersect zone with input vector (attributes from zone_fc retained)\n",
    "    arcpy.analysis.Intersect([zone_fc, dissolved_vector], out_path, \"ALL\")\n",
    "\n",
    "    # Step 2: Add overlap area (short field name)\n",
    "    arcpy.management.AddField(out_path, \"ov_area\", \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(out_path, [[\"ov_area\", \"AREA_GEODESIC\"]])\n",
    "\n",
    "    # Step 3: Get zone area from original features (via temporary copy)\n",
    "    #zone_copy = os.path.join(output_folder, \"zone_temp.shp\")\n",
    "    #arcpy.conversion.FeatureClassToFeatureClass(zone_fc, output_folder, out_name)\n",
    "    zone_copy_name = \"zone_temp.shp\"\n",
    "    zone_copy = os.path.join(out_temp_folder, zone_copy_name)\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(zone_fc, out_temp_folder, zone_copy_name)\n",
    "\n",
    "    arcpy.management.AddField(zone_copy, \"zn_area\", \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(zone_copy, [[\"zn_area\", \"AREA_GEODESIC\"]])\n",
    "\n",
    "    # Step 4: Join zone area to intersected features\n",
    "    arcpy.management.JoinField(out_path, zone_field, zone_copy, zone_field, [\"zn_area\"])\n",
    "\n",
    "    # Step 5: Add and calculate percent field\n",
    "    arcpy.management.AddField(out_path, \"pct\", \"FLOAT\")\n",
    "    arcpy.management.CalculateField(\n",
    "        out_path, \"pct\",\n",
    "        expression=\"(!ov_area! / !zn_area!) * 100 if !zn_area! else 0\",\n",
    "        expression_type=\"PYTHON3\"\n",
    "    )\n",
    "\n",
    "    #Step 6: Delete the temporary zone shapefile\n",
    "    arcpy.management.Delete(zone_copy)\n",
    "    \n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad8d21-8ecb-41bf-a2a1-37b8f3208225",
   "metadata": {},
   "source": [
    "#### Function to calculate ACREAGE overlap between zone_fc vector layer has any contact with the vector_path layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8d46e9-b015-4ff1-bf34-39b582c4e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_vector_acres(zone_fc, zone_field, vector_path, output_folder):\n",
    "    import os\n",
    "    import arcpy\n",
    "\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "    # Clean name for output shapefile\n",
    "    vector_base = os.path.splitext(os.path.basename(vector_path))[0]\n",
    "    out_name = f\"{vector_base[:32]}_acres.shp\"\n",
    "    out_path = os.path.join(output_folder, \"temp\", out_name)\n",
    "\n",
    "    out_temp_folder = os.path.join(output_folder, \"temp\")\n",
    "    \n",
    "    #Create OUTPUT folder which was pasased in as variable, and nested TEMP folder if they don't exist already\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(out_temp_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Delete existing output to avoid overwrite issues\n",
    "    if arcpy.Exists(out_path):\n",
    "        arcpy.management.Delete(out_path)\n",
    "\n",
    "    # New code to dissolve\n",
    "    dissolved_vector = os.path.join(out_temp_folder, \"dissolved_temp.shp\")\n",
    "    # Delete existing output to avoid overwrite issues\n",
    "    if arcpy.Exists(dissolved_vector):\n",
    "        arcpy.management.Delete(dissolved_vector)\n",
    "    arcpy.management.Dissolve(vector_path, dissolved_vector)\n",
    "    \n",
    "    # Intersect zone features with vector_path (attributes from zone_fc retained)\n",
    "    arcpy.analysis.Intersect([zone_fc, dissolved_vector], out_path, \"ALL\")\n",
    "\n",
    "    # Add area field (in acres)\n",
    "    arcpy.management.AddField(out_path, \"acres\", \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(out_path, [[\"acres\", \"AREA_GEODESIC\"]], area_unit=\"ACRES\")\n",
    "\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729d4f2f-92ff-4bb0-bc0f-036df360e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_spatialcount(zone_fc, zone_field, vector_path, output_folder, radius):\n",
    "    import os\n",
    "    import arcpy\n",
    "\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "    # Clean name for output shapefile\n",
    "    vector_base = os.path.splitext(os.path.basename(vector_path))[0]\n",
    "    out_name = f\"{vector_base[:32]}_count.shp\"\n",
    "    out_path = os.path.join(output_folder, \"temp\", out_name)\n",
    "\n",
    "    out_temp_folder = os.path.join(output_folder, \"temp\")\n",
    "    \n",
    "    #Create OUTPUT folder which was pasased in as variable, and nested TEMP folder if they don't exist already. Clean them if they do\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(out_temp_folder, exist_ok=True)\n",
    "\n",
    "    # Delete existing output to avoid overwrite issues\n",
    "    if arcpy.Exists(out_path):\n",
    "        arcpy.management.Delete(out_path)\n",
    "\n",
    "    # Step 1: Perform spatial join to count features within radius\n",
    "    spatial_join_temp = os.path.join(output_folder, \"temp_spjoin.shp\")\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=zone_fc,\n",
    "        join_features=vector_path,\n",
    "        out_feature_class=spatial_join_temp,\n",
    "        join_operation=\"JOIN_ONE_TO_MANY\",\n",
    "        join_type=\"KEEP_ALL\",\n",
    "        match_option=\"WITHIN_A_DISTANCE\",\n",
    "        search_radius=radius,\n",
    "        distance_field_name=None\n",
    "    )\n",
    "\n",
    "    # Step 2: Dissolve to get count of joined features per zone\n",
    "    arcpy.analysis.Statistics(\n",
    "        in_table=spatial_join_temp,\n",
    "        out_table=out_path,\n",
    "        statistics_fields=[[\"JOIN_FID\", \"COUNT\"]],\n",
    "        case_field=zone_field\n",
    "    )\n",
    "\n",
    "    # Step 3 (optional): Delete temp join file\n",
    "    arcpy.management.Delete(spatial_join_temp)\n",
    "\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa35eac-85c1-421d-a69a-6c16c53e3f19",
   "metadata": {},
   "source": [
    "#### Define a function to combine the multiple DBF files into one CSV. The field name in the CSV is taken from the DBF name, which originally was taken from the raster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3656494b-51d5-449f-acb9-0ebf0b9edb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_combine_tables(in_folder, out_folder, key_field, output_csv):\n",
    "    #key_field = \"GEOIDFQ\"\n",
    "    #output_csv = \"combined_zonal_stats.csv\"\n",
    "    #create list of DBF files in the in_folder\n",
    "    dbf_files = [f for f in os.listdir(in_folder) if f.lower().endswith(\".dbf\")]\n",
    "    merged_df = None\n",
    "\n",
    "    for dbf in dbf_files:\n",
    "        dbf_path = os.path.join(in_folder, dbf)\n",
    "        \n",
    "        # Get all non-geometry, non-OID fields\n",
    "        fields = [f.name for f in arcpy.ListFields(dbf_path) if f.type not in (\"Geometry\", \"OID\")]\n",
    "\n",
    "        if key_field not in fields or len(fields) < 2:\n",
    "            continue  # Skip if missing key or only one useful field\n",
    "\n",
    "        stat_field = fields[-1]  # Use rightmost field\n",
    "        table = arcpy.da.TableToNumPyArray(dbf_path, [key_field, stat_field])\n",
    "        df = pd.DataFrame(table)\n",
    "\n",
    "        # Rename stat field to the DBF base name\n",
    "        stat_name = os.path.splitext(dbf)[0]\n",
    "        df = df.rename(columns={stat_field: stat_name})\n",
    "\n",
    "        if merged_df is None:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, df, on=key_field, how=\"outer\")\n",
    "\n",
    "    # Save combined CSV\n",
    "    if merged_df is not None:\n",
    "        output_csv_path = os.path.join(out_folder, output_csv)\n",
    "        merged_df.to_csv(output_csv_path, index=False)\n",
    "        return output_csv_path\n",
    "    else:\n",
    "        raise ValueError(\"No valid DBFs found or no data to merge.\")\n",
    "\n",
    "    return output_csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676605a5-df98-4b72-8093-023a3c1788b2",
   "metadata": {},
   "source": [
    "#### Define a function to join the CSV back onto the CBG shapefile as a new output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc2409c-0657-4445-804c-419bcb4c4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_csv_join_to_shp(shapefile_cbg_path, merged_csv):\n",
    "    import os\n",
    "    import arcpy\n",
    "\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    # Output path based on CSV folder\n",
    "    output_folder = os.path.dirname(merged_csv)\n",
    "    output_shp = os.path.join(output_folder, \"combined_zonal_shapes.shp\")\n",
    "\n",
    "    # Assume GEOIDFQ is the common key\n",
    "    arcpy.management.MakeFeatureLayer(shapefile_cbg_path, \"cbg_layer\")\n",
    "    arcpy.management.MakeTableView(merged_csv, \"csv_table\")\n",
    "\n",
    "    arcpy.management.AddJoin(\"cbg_layer\", \"GEOIDFQ\", \"csv_table\", \"GEOIDFQ\", \"KEEP_COMMON\")\n",
    "\n",
    "    arcpy.management.CopyFeatures(\"cbg_layer\", output_shp)\n",
    "\n",
    "    # Clean up layers\n",
    "    arcpy.management.Delete(\"cbg_layer\")\n",
    "    arcpy.management.Delete(\"csv_table\")\n",
    "\n",
    "    return output_shp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2869b75d-ae1a-457e-94ac-f43bcd1f399a",
   "metadata": {},
   "source": [
    "#### Get the path of this notebook and use it to generate path for input shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214cb66d-01fe-451e-b440-71f3ce3d46b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a1da9f-739b-43c9-b1f8-7951f64eee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of this notebook: C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\n",
      "Location of CBG SHP: C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\cbg_kontur.shp\n",
      "Location for output: C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\output\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "shapefile_cbg = r\"input\\cbg_kontur.shp\"\n",
    "shapefile_cbg_path = os.path.join(current_dir, shapefile_cbg)\n",
    "output_folder_path = os.path.join(current_dir, \"output\")\n",
    "\n",
    "\n",
    "print(f\"Location of this notebook: {current_dir}\")\n",
    "print(f\"Location of CBG SHP: {shapefile_cbg_path}\")\n",
    "print(f\"Location for output: {output_folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a5774-07d1-4ff4-a76c-9652a2226afc",
   "metadata": {},
   "source": [
    "#### Define output folder and create it if it doesn't exist. Then clean it in case it has files already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da487fac-bfed-45f4-b521-bef7de5e84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join(current_dir, \"output\")\n",
    "temp_folder = os.path.join(current_dir, \"output\", \"temp\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "clean_folder(output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2e7aa-0164-475b-8176-aa86155afba2",
   "metadata": {},
   "source": [
    "#### The following lines run the zonal statistics function for each raster independently.  \n",
    "#### The outputs are all generated as DBF files with names originating from the rasters.  \n",
    "#### As many of these lines can be added as necessary, just change the inputs for the appropriate raster and statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75a94fe2-34a8-47f3-8a17-54d47f203872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\staterf_inann_mean.dbf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_zonal_stats(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\environmental\\staterf_inann.tif\", output_folder, \"MEAN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a95c393-f5ff-41c7-9bdc-1b36c32816cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\igtn_prob_test_maximum.dbf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_zonal_stats(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\environmental\\igtn_prob_test.tif\", output_folder, \"MAXIMUM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abbe8f1f-c6f9-413e-bc60-31b1158af366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\n10_landslide_susc_maximum.dbf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_zonal_stats(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\environmental\\n10_landslide_susc.tif\", output_folder, \"MAXIMUM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c7a2705-6acf-4960-88b2-c5beba55cbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\cat4_mom_slosh_hightide_maximum.dbf'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_zonal_stats(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\environmental\\cat4_mom_slosh_hightide.tif\", output_folder, \"MAXIMUM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c494894-9072-4e55-b2d3-99ed40812b41",
   "metadata": {},
   "source": [
    "#### The following lines run Spatial Satistics for each vector dataset independently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e777ba5-8ab6-4506-98ac-271266da01da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\slrxa_3pt2ft_intersect.dbf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_vector_match(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\environmental\\slrxa_3pt2ft.shp\", output_folder, \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1762f1a-a5fb-44ac-be71-292280402078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\slrxa_3pt2ft_pct.shp'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_vector_pct(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\environmental\\slrxa_3pt2ft.shp\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "170c4722-f440-437b-8237-fa96048ff51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\slrxa_3pt2ft_acres.shp'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_vector_acres(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\environmental\\slrxa_3pt2ft.shp\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03501b90-4faf-49a5-bbe2-6a76645d6af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\FEMA_SFHA_intersect.dbf'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_vector_match(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\environmental\\FEMA_SFHA.shp\", output_folder, \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5246953-d502-4bb7-b964-ae49dfa8f195",
   "metadata": {},
   "source": [
    "#### The follow lines run Spatial Joins to count features within a certain distance from each CBG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e6f4a2-7827-45c1-9f75-17ce81e1265d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\GITHUB\\\\CCSVI\\\\Scripts\\\\Spatial_Analysis\\\\output\\\\temp\\\\emergency_shelters_count.shp'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_spatialcount(shapefile_cbg_path, \"GEOIDFQ\", r\"C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\input\\facilities\\emergency_shelters.shp\", output_folder, \"0.5 miles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e050d8-0645-45d7-8988-6bc1ec0ff112",
   "metadata": {},
   "source": [
    "#### This runs the function to take the previously generated DBF files and merge them all to one CSV file with fieldnames from the DBFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b136eb52-c33f-4d95-97e3-91e51d6c93b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\GITHUB\\CCSVI\\Scripts\\Spatial_Analysis\\output\\combined_zonal_stats.csv\n"
     ]
    }
   ],
   "source": [
    "merged_csv = func_combine_tables(temp_folder,output_folder_path, \"GEOIDFQ\", \"combined_zonal_stats.csv\")\n",
    "print(merged_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48148c-be8f-48a7-b482-72918912ae1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c92893c3-8907-42be-8e0f-3ff970792f33",
   "metadata": {},
   "source": [
    "#### This joins the CSV back onto the shapefile as a new output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbfe3ae0-8b57-4c9d-a3fd-015cf346fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(func_csv_join_to_shp(shapefile_cbg_path, merged_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f011c7c-7f0f-46a5-90e6-68a7ec29eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Finished at:\", time_mod.strftime(\"%Y-%m-%d %H:%M:%S\", time_mod.localtime(time_mod.time())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
